{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import numpy\n",
    "import codecs\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "from Bio import Medline\n",
    "from scipy import spatial\n",
    "from random import shuffle\n",
    "#from pattern.en import tag\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn import feature_extraction\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from contractions import CONTRACTION_MAP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(string):\n",
    "    # Preprocesses a string by lowercasing, trimming, and removing non-alphanumeric\n",
    "    return \" \".join(re.findall(r'\\w+', string, flags=re.UNICODE)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(word):\n",
    "    return WNL.lemmatize(word).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(lst):\n",
    "    # Removing stopwords from a list of tokens\n",
    "    return [w for w in lst if w not in feature_extraction.text.ENGLISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_lemmas(string):\n",
    "    # Returns tokenized words\n",
    "    return [normalize(token) for token in remove_stopwords(nltk.word_tokenize(string))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNL = WordNetLemmatizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list = stopword_list + ['mr', 'mrs', 'come', 'go', 'get', 'tell', 'listen', 'one', 'two', 'three', \n",
    "'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero', 'join', 'find', 'make', 'say', 'ask','tell', 'see', 'try', 'back', 'also']\n",
    "stopword_pubmed = stopword_list + ['a', 'about', 'again', 'all', 'almost', 'also', 'although', 'always', 'among', 'an', 'and', \n",
    "'another', 'any', 'are', 'as', 'at','be', 'because', 'been', 'before', 'being', 'between', 'both', 'but', 'by','can', 'could',\n",
    "'did', 'do', 'does', 'done', 'due', 'during','each', 'either', 'enough', 'especially', 'etc','for', 'found', 'from', 'further',\n",
    "'had', 'has', 'have', 'having', 'here', 'how', 'however','i', 'if', 'in', 'into', 'is', 'it', 'its', 'itself','just','kg', 'km',\n",
    "'made', 'mainly', 'make', 'may', 'mg', 'might', 'ml', 'mm', 'most', 'mostly', 'must','nearly', 'neither', 'no', 'nor','obtained', \n",
    "'of', 'often', 'on', 'our', 'overall','perhaps', 'pmid','quite','rather', 'really', 'regarding','seem', 'seen', 'several', 'should', \n",
    "'show', 'showed', 'shown', 'shows', 'significantly', 'since', 'so', 'some', 'such', 'than', 'that', 'the', 'their', 'theirs', \n",
    "'them', 'then', 'there', 'therefore', 'these', 'they', 'this', 'those', 'through', 'thus', 'to','upon', 'use', 'used', 'using',\n",
    "'various', 'very', 'was', 'we', 'were', 'what', 'when', 'which', 'while', 'with', 'within', 'without', 'would']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "filelist = os.listdir(r\"Task 2\\training\\extracted_data\")\n",
    "for datei in filelist:\n",
    "    if datei.endswith('.pids'):\n",
    "        frame = pd.read_table(r\"Task 2\\training\\extracted_data\\\\\"+datei, names = ['PMID'], encoding='utf8')\n",
    "        df = df.append(frame)\n",
    "df = pd.DataFrame(df.PMID.str.split(' ', 1).tolist(), columns=['TOPIC','PMID'])\n",
    "#LISTE mit PMIDS erstellen\n",
    "pmids = df['PMID'].tolist()\n",
    "# GET Abstracts \n",
    "pmid_list = []\n",
    "title_list = []\n",
    "ab_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Pmids, Titles and Abstracts to the Lists\n",
    "with open(\"pubmed.txt\") as handle:\n",
    "    record = Medline.read(handle)\n",
    "    for record in Medline.parse(handle):\n",
    "        ab_list.append(record.get(\"AB\"))\n",
    "        title_list.append(record.get(\"TI\"))\n",
    "        pmid_list.append(record.get(\"PMID\"))\n",
    "#Build Dicts from the Information       \n",
    "pmid_title = dict(zip(pmid_list,title_list))\n",
    "pmid_ab = dict(zip(pmid_list,ab_list))\n",
    "#REMOVE Entrys with None Values\n",
    "pmid_ab_final = dict((k, v) for k, v in pmid_ab.items() if v)\n",
    "pmid_list2=[]\n",
    "ab_list2=[]\n",
    "pmid_list2=list(pmid_ab_final.keys())\n",
    "ab_list2=list(pmid_ab_final.values())\n",
    "df2 = pd.DataFrame(list(zip(pmid_list,ab_list)))\n",
    "df2.columns=['PMID','ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized...\n"
     ]
    }
   ],
   "source": [
    "#CREATE TOPIC und SYSTEMATIC REVIEW TITLE from the .TITLE Files\n",
    "df3 = pd.DataFrame()\n",
    "filelist = os.listdir(r\"Task 2\\training\\extracted_data\")\n",
    "for datei in filelist:\n",
    "    if datei.endswith('.title'):\n",
    "        frame = pd.read_table(r\"Task 2\\training\\extracted_data\\\\\"+datei, names = ['TITLE'], encoding='utf8')\n",
    "        df3 = df3.append(frame)\n",
    "df3 = pd.DataFrame(df3.TITLE.str.split(' ',1).tolist(), columns = ['TOPIC','TITLE'])\n",
    "df3.columns= ['TOPIC','SYS TITLE']\n",
    "topics = df['TOPIC'].tolist()\n",
    "titles = df3['SYS TITLE'].tolist()\n",
    "print(\"initialized...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2count(body):\n",
    "    freq = defaultdict(int)\n",
    "    for word in body:\n",
    "        freq[word] += 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences2vectors(sentences):\n",
    "    body_vectors = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence\n",
    "        cnt = 0\n",
    "        body_vector = np.array([0.0] * 300)\n",
    "        for word in words:\n",
    "            if word in word_vectors:\n",
    "                body_vector = body_vector + word_vectors[word]\n",
    "                cnt += 1\n",
    "        if cnt > 0:\n",
    "            body_vector /= cnt\n",
    "            body_vector /= np.linalg.norm(body_vector)\n",
    "        body_vectors.append(body_vector)\n",
    "    return body_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(title, body):\n",
    "    title_vectors = sentences2vectors([title])\n",
    "    title_vector = title_vectors[0]\n",
    "    body_vectors = sentences2vectors(body)\n",
    "    \n",
    "    max_sim = -1\n",
    "    diff_vector = title_vector\n",
    "    for body_vector in body_vectors:\n",
    "        similarity = 1 - spatial.distance.cosine(title_vector, body_vector)\n",
    "        if similarity > max_sim:\n",
    "            max_sim = similarity\n",
    "            diff_vector = title_vector - body_vector\n",
    "    features = [max_sim]\n",
    "    for v in diff_vector:\n",
    "        features.append(v)\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_overlaps(title, body, idf):\n",
    "    features = []\n",
    "\n",
    "    words_in_body = text2count(body)\n",
    "    words_in_title = text2count(title)\n",
    "\n",
    "    maximum, maximum_cnt = 0.0, 0.0\n",
    "    for (word, cnt_title) in words_in_title.items():\n",
    "        maximum += cnt_title * idf[word]\n",
    "        maximum_cnt += cnt_title\n",
    "\n",
    "    overlaps, overlap_cnt = 0, 0\n",
    "    for (word, cnt_title) in words_in_title.items():\n",
    "        if word in words_in_body:\n",
    "            tf = min(cnt_title, words_in_body[word])\n",
    "            overlap_cnt += tf\n",
    "            overlaps += tf * idf[word]\n",
    "    features += [overlaps, overlaps / (maximum+0.001), overlap_cnt, overlap_cnt / (maximum_cnt+0.001)]\n",
    "\n",
    "    words_in_body = text2count(body[:len(title) * 4])\n",
    "    overlaps, overlap_cnt = 0, 0\n",
    "    for (word, cnt_title) in words_in_title.items():\n",
    "        if word in words_in_body:\n",
    "            tf = min(cnt_title, words_in_body[word])\n",
    "            overlap_cnt += tf\n",
    "            overlaps += tf * idf[word]\n",
    "    features += [overlaps, overlaps / (maximum+0.001), overlap_cnt, overlap_cnt / (maximum_cnt+0.001)]\n",
    "\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title2vector(title, word2vec, idf):\n",
    "    vector = np.array([0.0] * 300)\n",
    "    cnt = 0\n",
    "    for word in title:\n",
    "        if word in word2vec:\n",
    "            vector += word2vec[word]\n",
    "            cnt += 1\n",
    "    if cnt > 0:\n",
    "        vector /= cnt\n",
    "        vector /= np.linalg.norm(vector)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(title, body_sentence, idf):\n",
    "    words_in_body = text2count(body_sentence)\n",
    "    words_in_title = text2count(title)\n",
    "\n",
    "    maximum, maximum_cnt = 0.0, 0.0\n",
    "    for (word, cnt_title) in words_in_title.items():\n",
    "        maximum += cnt_title * idf[word]\n",
    "        maximum_cnt += cnt_title\n",
    "\n",
    "    overlaps, overlap_cnt = 0, 0\n",
    "    for (word, cnt_title) in words_in_title.items():\n",
    "        if word in words_in_body:\n",
    "            tf = min(cnt_title, words_in_body[word])\n",
    "            overlap_cnt += tf\n",
    "            overlaps += tf * idf[word]\n",
    "    return overlaps / (maximum_cnt+0.001), overlap_cnt / (maximum_cnt+0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarities(title, body_sentences, word2vec, idf):\n",
    "    max_overlap, max_overlap_cnt = 0, 0\n",
    "    #title_vector = title2vector(title, word2vec, idf)\n",
    "    max_sim = -1\n",
    "    best_vector = np.array([0.0] * 300)\n",
    "\n",
    "    supports = []\n",
    "    for sub_body in body_sentences:\n",
    "        #sub_body_vector = title2vector(sub_body, word2vec, idf)\n",
    "\n",
    "        cur_overlap, cur_overlap_cnt = compute_overlap(title, sub_body, idf)\n",
    "\n",
    "        max_overlap = max(max_overlap, cur_overlap)\n",
    "        max_overlap_cnt = max(max_overlap_cnt, cur_overlap_cnt)\n",
    "\n",
    "        similarity = 0\n",
    "#         for i in range(300):\n",
    "#             similarity += title_vector[i] * sub_body_vector[i]\n",
    "#         if similarity > max_sim:\n",
    "#             max_sim = similarity\n",
    "            #best_vector = sub_body_vector\n",
    "\n",
    "        #supports.append(similarity)\n",
    "\n",
    "    #features = [max_overlap, max_overlap_cnt, max(supports), min(supports)]\n",
    "\n",
    "    #for v in title_vector - best_vector:\n",
    "    #    features.append(v)\n",
    "#     for v in best_vector:\n",
    "#         features.append(v)\n",
    "#     for v in title_vector:\n",
    "#         features.append(v)\n",
    "    return max_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word2vec...\n",
      "word2vec loaded\n"
     ]
    }
   ],
   "source": [
    "word2vec = {}\n",
    "print ('loading word2vec...')\n",
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "for word in word_vectors.vocab:\n",
    "    word2vec[normalize(word)] = word_vectors[word]\n",
    "print ('word2vec loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(title, abstract, idf, word2vec):\n",
    "    return [lexical_overlaps(title, abstract, idf), semantic_similarities(title, abstract, word2vec, idf), cosine_sim(title, abstract), levenshtein(title, abstract), lexical_overlaps(title, abstract, idf) + semantic_similarities(title, abstract, word2vec, idf) + cosine_sim(title, abstract) + levenshtein(title, abstract)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36AMD64\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Python36AMD64\\lib\\site-packages\\pandas\\io\\parsers.py:2227: FutureWarning: split() requires a non-empty pattern match.\n",
      "  yield pat.split(line.strip())\n",
      "C:\\Python36AMD64\\lib\\site-packages\\pandas\\io\\parsers.py:2229: FutureWarning: split() requires a non-empty pattern match.\n",
      "  yield pat.split(line.strip())\n"
     ]
    }
   ],
   "source": [
    "qrel_file = pd.read_table(r\"Task 2/training/qrels/qrel_abs_train\", header=None, sep='\\s*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel_lists = np.array(qrel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CD010438', 0, 4461416, 0], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = np.array(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_dict = {}\n",
    "for i in range(len(titles_list)):\n",
    "    titles_dict[titles_list[i][0]] = titles_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urine tests for Down's syndrome screening\n"
     ]
    }
   ],
   "source": [
    "print(titles_dict['CD011984'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['CD010438', '0', '4461416', '0'],\n",
       "       ['CD010438', '0', '19762299', '0'],\n",
       "       ['CD010438', '0', '16607076', '0'],\n",
       "       ...,\n",
       "       ['CD007394', '0', '2194959', '0'],\n",
       "       ['CD007394', '0', '1633294', '0'],\n",
       "       ['CD007394', '0', '2532389', '0']], dtype='<U64')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_file = np.array(qrel_file, dtype=str)\n",
    "qrel_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_list = np.array(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_dict = {}\n",
    "for i in range(len(pmid_list)):\n",
    "    pmid_dict[pmid_list[i][0]] = pmid_list[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_titles = []\n",
    "pmid_abstracts = []\n",
    "relevancy_labels = []\n",
    "for i in range(len(qrel_file)):\n",
    "    if qrel_file[i][0] in titles_dict and qrel_file[i][2] in pmid_dict and pmid_dict[qrel_file[i][2]] != 'None':\n",
    "        topic_titles.append(titles_dict[qrel_file[i][0]])\n",
    "        pmid_abstracts.append(pmid_dict[qrel_file[i][2]])\n",
    "        relevancy_labels.append(qrel_file[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_frame = pd.DataFrame({'Topics': topic_titles, 'Abstracts': pmid_abstracts, 'Labels': relevancy_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_frame.dropna(how='any', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now all the rows with None values have been removed.\n",
    "pmid_abstracts = np.array(dataset_frame.Abstracts)\n",
    "topic_titles = np.array(dataset_frame.Topics)\n",
    "relevancy_labels = np.array(dataset_frame.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118593 118593 118593\n"
     ]
    }
   ],
   "source": [
    "print(len(pmid_abstracts), len(topic_titles), len(relevancy_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = defaultdict(float)\n",
    "for content in pmid_abstracts:\n",
    "    #print(content)\n",
    "    for word in set(tokenized_lemmas(content)):\n",
    "        idf[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in idf:\n",
    "    idf[word] = log(len(pmid_abstracts) / idf[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118593 118593 118593\n"
     ]
    }
   ],
   "source": [
    "print(len(pmid_abstracts), len(topic_titles), len(relevancy_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     train_X.append(extract_features(abstract=pmid_abstracts[i], idf=idf, title=topic_titles[i], word2vec=word2vec))\n",
    "# Uncomment the code if the features are being calculated for the first time, otherwise, we'll read them from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_X = pickle.load(open(\"trainX.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118693\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X = train_X[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118593\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame()\n",
    "filelist_test = os.listdir(r\"Task 2\\testing\\extracted_data\")\n",
    "for datei in filelist_test:\n",
    "    if datei.endswith('.pids'):\n",
    "        frame = pd.read_table(r\"Task 2\\testing\\extracted_data\\\\\"+datei, names = ['PMID'], encoding='utf8')\n",
    "        df_test = df_test.append(frame)\n",
    "df_test = pd.DataFrame(df_test.PMID.str.split(' ', 1).tolist(), columns=['TOPIC','PMID'])\n",
    "#LISTE mit PMIDS erstellen\n",
    "pmids_test = df_test['PMID'].tolist()\n",
    "# GET Abstracts \n",
    "pmid_list_test = []\n",
    "title_list_test = []\n",
    "ab_list_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Pmids, Titles and Abstracts to the Lists\n",
    "with open(\"pubmed.txt\") as handle:\n",
    "    record = Medline.read(handle)\n",
    "    for record in Medline.parse(handle):\n",
    "        ab_list_test.append(record.get(\"AB\"))\n",
    "        title_list_test.append(record.get(\"TI\"))\n",
    "        pmid_list_test.append(record.get(\"PMID\"))\n",
    "#Build Dicts from the Information       \n",
    "pmid_title_test = dict(zip(pmid_list_test,title_list_test))\n",
    "pmid_ab_test = dict(zip(pmid_list_test,ab_list_test))\n",
    "#REMOVE Entrys with None Values\n",
    "pmid_ab_final_test = dict((k, v) for k, v in pmid_ab_test.items() if v)\n",
    "pmid_list2_test=[]\n",
    "ab_list2_test=[]\n",
    "pmid_list2_test=list(pmid_ab_final_test.keys())\n",
    "ab_list2_test=list(pmid_ab_final_test.values())\n",
    "df2_test = pd.DataFrame(list(zip(pmid_list_test,ab_list_test)))\n",
    "df2_test.columns=['PMID','ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized...\n"
     ]
    }
   ],
   "source": [
    "#CREATE TOPIC und SYSTEMATIC REVIEW TITLE from the .TITLE Files\n",
    "df3_test = pd.DataFrame()\n",
    "filelist_test = os.listdir(r\"Task 2\\testing\\extracted_data\")\n",
    "for datei in filelist_test:\n",
    "    if datei.endswith('.title'):\n",
    "        frame = pd.read_table(r\"Task 2\\testing\\extracted_data\\\\\"+datei, names = ['TITLE'], encoding='utf8')\n",
    "        df3_test = df3_test.append(frame)\n",
    "df3_test = pd.DataFrame(df3_test.TITLE.str.split(' ',1).tolist(), columns = ['TOPIC','TITLE'])\n",
    "df3_test.columns= ['TOPIC','SYS TITLE']\n",
    "topics_test = df_test['TOPIC'].tolist()\n",
    "titles_test = df3_test['SYS TITLE'].tolist()\n",
    "print(\"initialized...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36AMD64\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Python36AMD64\\lib\\site-packages\\pandas\\io\\parsers.py:2227: FutureWarning: split() requires a non-empty pattern match.\n",
      "  yield pat.split(line.strip())\n",
      "C:\\Python36AMD64\\lib\\site-packages\\pandas\\io\\parsers.py:2229: FutureWarning: split() requires a non-empty pattern match.\n",
      "  yield pat.split(line.strip())\n"
     ]
    }
   ],
   "source": [
    "qrel_file_test = pd.read_table(r\"Task 2/testing/qrels/qrel_abs_test.txt\", header=None, sep='\\s*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel_lists_test = np.array(qrel_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CD007431', 0, 7072537, 0], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_lists_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list_test = np.array(df3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_dict_test = {}\n",
    "for i in range(len(titles_list_test)):\n",
    "    titles_dict_test[titles_list_test[i][0]] = titles_list_test[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['CD007431', '0', '7072537', '0'],\n",
       "       ['CD007431', '0', '8748845', '0'],\n",
       "       ['CD007431', '0', '3819738', '0'],\n",
       "       ...,\n",
       "       ['CD009925', '0', '15298970', '0'],\n",
       "       ['CD009925', '0', '10377014', '0'],\n",
       "       ['CD009925', '0', '2664755', '0']], dtype='<U64')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel_file_test = np.array(qrel_file_test, dtype=str)\n",
    "qrel_file_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_list_test = np.array(df2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid_dict_test = {}\n",
    "for i in range(len(pmid_list_test)):\n",
    "    pmid_dict_test[pmid_list_test[i][0]] = pmid_list_test[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_titles_test = []\n",
    "pmid_abstracts_test = []\n",
    "relevancy_labels_test = []\n",
    "for i in range(len(qrel_file_test)):\n",
    "    if qrel_file_test[i][0] in titles_dict_test and qrel_file_test[i][2] in pmid_dict_test and pmid_dict_test[qrel_file_test[i][2]] != 'None':\n",
    "        topic_titles_test.append(titles_dict_test[qrel_file_test[i][0]])\n",
    "        pmid_abstracts_test.append(pmid_dict_test[qrel_file_test[i][2]])\n",
    "        relevancy_labels_test.append(qrel_file_test[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_frame_test = pd.DataFrame({'Topics': topic_titles_test, 'Abstracts': pmid_abstracts_test, 'Labels': relevancy_labels_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_frame_test.dropna(how='any', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now all the rows with None values have been removed.\n",
    "pmid_abstracts_test = np.array(dataset_frame_test.Abstracts)\n",
    "topic_titles_test = np.array(dataset_frame_test.Topics)\n",
    "relevancy_labels_test = np.array(dataset_frame_test.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21872 21872 21872\n"
     ]
    }
   ],
   "source": [
    "print(len(pmid_abstracts_test), len(topic_titles_test), len(relevancy_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36AMD64\\lib\\site-packages\\scipy\\spatial\\distance.py:649: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(pmid_abstracts_test)):\n",
    "#     test_X.append(extract_features(abstract=pmid_abstracts_test[i], idf=idf, title=topic_titles_test[i], word2vec=word2vec))\n",
    "#Dont need these if you have the testX.pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pickle.load(open(\"testX.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(learning_rate=0.01, silent=False, base_score=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevancy_labels_int = np.array(relevancy_labels, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevancy_labels_test_int = np.array(relevancy_labels_test, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.1, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=False, subsample=1)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(np.array(train_X), relevancy_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36AMD64\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9685899780541332"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_X, relevancy_labels_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36AMD64\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2319"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(relevancy_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(relevancy_labels_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = MLPClassifier(activation='logistic', hidden_layer_sizes=(2), alpha=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-06, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=2, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(train_X, relevancy_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = clf2.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pklFil = open(\"testX.pkl\", \"wb\")\n",
    "pickle.dump(obj=test_X, file=pklFil)\n",
    "pklFil.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
